{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54859375-617e-485f-aaed-8766581b6215",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing_extensions in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (4.14.1)\nRequirement already satisfied: mlflow in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (3.1.4)\nRequirement already satisfied: mlflow-skinny==3.1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from mlflow) (3.1.4)\nRequirement already satisfied: Flask<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from mlflow) (3.1.1)\nRequirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from mlflow) (1.16.4)\nRequirement already satisfied: docker<8,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from mlflow) (7.1.0)\nRequirement already satisfied: graphene<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from mlflow) (3.4.3)\nRequirement already satisfied: gunicorn<24 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from mlflow) (23.0.0)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow) (3.7.2)\nRequirement already satisfied: numpy<3 in /databricks/python3/lib/python3.11/site-packages (from mlflow) (1.23.5)\nRequirement already satisfied: pandas<3 in /databricks/python3/lib/python3.11/site-packages (from mlflow) (1.5.3)\nRequirement already satisfied: pyarrow<21,>=4.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow) (14.0.1)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow) (1.3.0)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow) (1.11.1)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from mlflow) (2.0.42)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (5.5.0)\nRequirement already satisfied: click<9,>=7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (8.2.1)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (3.0.0)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (0.40.0)\nRequirement already satisfied: fastapi<1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (0.116.1)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (3.1.43)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (6.0.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (1.36.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (1.36.0)\nRequirement already satisfied: packaging<26 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (23.2)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (5.29.3)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (2.11.7)\nRequirement already satisfied: pyyaml<7,>=5.1 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (6.0)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (2.31.0)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (0.5.1)\nRequirement already satisfied: uvicorn<1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from mlflow-skinny==3.1.4->mlflow) (0.35.0)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.16)\nRequirement already satisfied: blinker>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: itsdangerous>=2.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: jinja2>=3.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.6)\nRequirement already satisfied: markupsafe>=2.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from Flask<4->mlflow) (3.0.2)\nRequirement already satisfied: werkzeug>=3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.6)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /databricks/python3/lib/python3.11/site-packages (from graphene<4->mlflow) (2.8.2)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.0.5)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (10.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.0.9)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas<3->mlflow) (2022.7)\nRequirement already satisfied: joblib>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (2.2.0)\nRequirement already satisfied: greenlet>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.3)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (2.35.0)\nRequirement already satisfied: starlette<0.48.0,>=0.40.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny==3.1.4->mlflow) (0.47.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.4->mlflow) (4.0.11)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.4->mlflow) (3.11.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.4->mlflow) (0.57b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.4->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.4->mlflow) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.4->mlflow) (0.4.1)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.4->mlflow) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.4->mlflow) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.4->mlflow) (2023.7.22)\nRequirement already satisfied: h11>=0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from uvicorn<1->mlflow-skinny==3.1.4->mlflow) (0.16.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.4->mlflow) (5.0.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (4.9)\nRequirement already satisfied: anyio<5,>=3.6.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.4->mlflow) (4.9.0)\nRequirement already satisfied: sniffio>=1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.4->mlflow) (1.3.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (0.4.8)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install typing_extensions mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7f6b255-9d63-40ab-b0a4-4f31b15f0e10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "from pprint import pprint\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a6607a1-bd32-4cd9-8b55-8db7e7b1b529",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/4230816160263178', creation_time=1754017391097, experiment_id='4230816160263178', last_update_time=1754017393582, lifecycle_stage='active', name='/Shared/MLflow-CE/extras/2_mlflow_project', tags={'mlflow.experiment.sourceName': '/Shared/MLflow-CE/extras/2_mlflow_project',\n 'mlflow.experimentType': 'NOTEBOOK',\n 'mlflow.ownerEmail': 'dimitar_pg13@hotmail.com',\n 'mlflow.ownerId': '3716595958488557'}>, <Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/4230816160263163', creation_time=1753938387036, experiment_id='4230816160263163', last_update_time=1753984401622, lifecycle_stage='active', name='/Shared/MLflow-CE/extras/1_get_started_fun_lab_lr', tags={'mlflow.experiment.sourceName': '/Shared/MLflow-CE/extras/1_get_started_fun_lab_lr',\n 'mlflow.experimentType': 'NOTEBOOK',\n 'mlflow.ownerEmail': 'dimitar_pg13@hotmail.com',\n 'mlflow.ownerId': '3716595958488557'}>, <Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/4230816160263147', creation_time=1753936520333, experiment_id='4230816160263147', last_update_time=1753936540227, lifecycle_stage='active', name='/Shared/MLflow-CE/extras/0_get_started_fun_lab', tags={'mlflow.databricks.filesystem.experiment_permissions_check': 'test',\n 'mlflow.experiment.sourceName': '/Shared/MLflow-CE/extras/0_get_started_fun_lab',\n 'mlflow.experimentType': 'NOTEBOOK',\n 'mlflow.note.content': 'This is a fake cup cake predicion experiment: Getting '\n                        'started with MLflow Workhop Series Part 1 ...',\n 'mlflow.ownerEmail': 'dimitar_pg13@hotmail.com',\n 'mlflow.ownerId': '3716595958488557'}>, <Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/4230816160263187', creation_time=1753935387217, experiment_id='4230816160263187', last_update_time=1753935406816, lifecycle_stage='active', name='/Shared/MLflow-CE/2_banknote_classification_lab', tags={'mlflow.databricks.filesystem.experiment_permissions_check': 'test',\n 'mlflow.experiment.sourceName': '/Shared/MLflow-CE/2_banknote_classification_lab',\n 'mlflow.experimentType': 'NOTEBOOK',\n 'mlflow.ownerEmail': 'dimitar_pg13@hotmail.com',\n 'mlflow.ownerId': '3716595958488557'}>, <Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/4230816160263195', creation_time=1753930029394, experiment_id='4230816160263195', last_update_time=1753934883592, lifecycle_stage='active', name='/Shared/MLflow-CE/1_petrol_regression_lab', tags={'mlflow.databricks.filesystem.experiment_permissions_check': 'test',\n 'mlflow.experiment.sourceName': '/Shared/MLflow-CE/1_petrol_regression_lab',\n 'mlflow.experimentType': 'NOTEBOOK',\n 'mlflow.ownerEmail': 'dimitar_pg13@hotmail.com',\n 'mlflow.ownerId': '3716595958488557'}>, <Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/2334465887741875', creation_time=1753924511322, experiment_id='2334465887741875', last_update_time=1753924511322, lifecycle_stage='active', name='/Users/dimitar_pg13@hotmail.com/test_mlflow_01', tags={'mlflow.experiment.sourceName': '/Users/dimitar_pg13@hotmail.com/test_mlflow_01',\n 'mlflow.experimentType': 'NOTEBOOK',\n 'mlflow.ownerEmail': 'dimitar_pg13@hotmail.com',\n 'mlflow.ownerId': '3716595958488557'}>]\n"
     ]
    }
   ],
   "source": [
    "all_experiments = client.search_experiments()\n",
    "\n",
    "print(all_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "472691cf-0478-47e9-a8c5-29c8fefa8aaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lifecycle_stage': 'active',\n 'name': '/Shared/MLflow-CE/extras/0_get_started_fun_lab'}\n"
     ]
    }
   ],
   "source": [
    "default_experiment = [\n",
    "    {\"name\": experiment.name, \"lifecycle_stage\": experiment.lifecycle_stage}\n",
    "    for experiment in all_experiments\n",
    "    if experiment.name == \"/Shared/MLflow-CE/extras/0_get_started_fun_lab\"\n",
    "][0]\n",
    "\n",
    "pprint(default_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5d7b7f9-9634-4058-804d-5dfaacdc9210",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Provide an experiment description that will appear on the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa0ee41f-e712-4b4a-b3c0-a66dbb009051",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "experiment_description = (\n",
    "    \"This is grocery-forecasting experiment\"\n",
    "    \"The experiment contains the produce models for apples\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05002389-5501-4426-b55e-7f68f4740c03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Provide searchable tags that define the characteristics of Runs that will be part of this experiemnt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ffff97a-4fbf-4223-bb7f-8ef4ffaca098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "experiment_tags = {\n",
    "    \"project_name\": \"grocery-forecasting\",\n",
    "    \"store_dept\": \"produce\",\n",
    "    \"team\": \"stores-ml\",\n",
    "    \"project_quarter\": \"Q3-2023\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f5d1bf6-bec7-419c-a5bb-fce56b0a00b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Create an experiment , providing a unique name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9c9aec0-22f2-4a68-920a-3e22ead6eb45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "produce_apples_experiment = client.create_experiment(\n",
    "    name=\"/Users/dimitar_pg13@hotmail.com/Apple_Models\", tags=experiment_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58ebb1bc-4de9-4f22-8c78-b18f92aa6111",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_experiment_id': '2387429575046603', '_name': '/Users/dimitar_pg13@hotmail.com/Apple_Models', '_artifact_location': 'dbfs:/databricks/mlflow-tracking/2387429575046603', '_lifecycle_stage': 'active', '_tags': {'mlflow.experiment.sourceName': '/Users/dimitar_pg13@hotmail.com/Apple_Models', 'mlflow.ownerId': '3716595958488557', 'mlflow.ownerEmail': 'dimitar_pg13@hotmail.com', 'mlflow.experimentType': 'MLFLOW_EXPERIMENT', 'mlflow.experimentKind': 'custom_model_development', 'mlflow.note.content': 'This is grocery-forecasting experimentThe experiment contains the produce models for apples', 'project_name': 'grocery-forecasting', 'project_quarter': 'Q3-2023', 'store_dept': 'produce', 'team': 'stores-ml'}, '_creation_time': 1754098322707, '_last_update_time': 1754098322707}\n"
     ]
    }
   ],
   "source": [
    "apples_experiment = client.search_experiments(\n",
    "    filter_string=\"tags.`project_name` = 'grocery-forecasting'\"\n",
    ")\n",
    "\n",
    "print(vars(apples_experiment[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f77f8f21-b654-44a7-8243-ca5aab817ad5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Synthetic Data Creation\n",
    "In order to produce some meaningful data (and a model) for us to log to MLflow, we'll use a apple-related dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3663ae23-6aa0-4a46-a0df-c0c588dcb4b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Defining a dataset generator\n",
    "For our examples to work, we're going to need something that can actually fit, but not something that fits too well. We're going to be training multiple iterations in order to show the effect of modifying our model's hyperparameters, so there needs to be some amount of unexplained variance in the feature set. However, we need some degree of correlation between our target variable (demand, in the case of our apples sales data that we want to predict) and the feature set.\n",
    "\n",
    "We can introduce this correlation by crafting a relationship between our features and our target. The random elements of some of the factors will handle the unexplained variance portion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f0e2bfa-3cb4-4b03-8858-33a42baf2dc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def generate_apple_sales_data_with_promo_adjustment(\n",
    "    base_demand: int = 1000, n_rows: int = 5000\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset for predicting apple sales demand with seasonality\n",
    "    and inflation.\n",
    "\n",
    "    This function creates a pandas DataFrame with features relevant to apple sales.\n",
    "    The features include date, average_temperature, rainfall, weekend flag, holiday flag,\n",
    "    promotional flag, price_per_kg, and the previous day's demand. The target variable,\n",
    "    'demand', is generated based on a combination of these features with some added noise.\n",
    "\n",
    "    Args:\n",
    "        base_demand (int, optional): Base demand for apples. Defaults to 1000.\n",
    "        n_rows (int, optional): Number of rows (days) of data to generate. Defaults to 5000.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with features and target variable for apple sales prediction.\n",
    "\n",
    "    Example:\n",
    "        >>> df = generate_apple_sales_data_with_seasonality(base_demand=1200, n_rows=6000)\n",
    "        >>> df.head()\n",
    "    \"\"\"\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(9999)\n",
    "\n",
    "    # Create date range\n",
    "    dates = [datetime.now() - timedelta(days=i) for i in range(n_rows)]\n",
    "    dates.reverse()\n",
    "\n",
    "    # Generate features\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"date\": dates,\n",
    "            \"average_temperature\": np.random.uniform(10, 35, n_rows),\n",
    "            \"rainfall\": np.random.exponential(5, n_rows),\n",
    "            \"weekend\": [(date.weekday() >= 5) * 1 for date in dates],\n",
    "            \"holiday\": np.random.choice([0, 1], n_rows, p=[0.97, 0.03]),\n",
    "            \"price_per_kg\": np.random.uniform(0.5, 3, n_rows),\n",
    "            \"month\": [date.month for date in dates],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Introduce inflation over time (years)\n",
    "    df[\"inflation_multiplier\"] = (\n",
    "        1 + (df[\"date\"].dt.year - df[\"date\"].dt.year.min()) * 0.03\n",
    "    )\n",
    "\n",
    "    # Incorporate seasonality due to apple harvests\n",
    "    df[\"harvest_effect\"] = np.sin(2 * np.pi * (df[\"month\"] - 3) / 12) + np.sin(\n",
    "        2 * np.pi * (df[\"month\"] - 9) / 12\n",
    "    )\n",
    "\n",
    "    # Modify the price_per_kg based on harvest effect\n",
    "    df[\"price_per_kg\"] = df[\"price_per_kg\"] - df[\"harvest_effect\"] * 0.5\n",
    "\n",
    "    # Adjust promo periods to coincide with periods lagging peak harvest by 1 month\n",
    "    peak_months = [4, 10]  # months following the peak availability\n",
    "    df[\"promo\"] = np.where(\n",
    "        df[\"month\"].isin(peak_months),\n",
    "        1,\n",
    "        np.random.choice([0, 1], n_rows, p=[0.85, 0.15]),\n",
    "    )\n",
    "\n",
    "    # Generate target variable based on features\n",
    "    base_price_effect = -df[\"price_per_kg\"] * 50\n",
    "    seasonality_effect = df[\"harvest_effect\"] * 50\n",
    "    promo_effect = df[\"promo\"] * 200\n",
    "\n",
    "    df[\"demand\"] = (\n",
    "        base_demand\n",
    "        + base_price_effect\n",
    "        + seasonality_effect\n",
    "        + promo_effect\n",
    "        + df[\"weekend\"] * 300\n",
    "        + np.random.normal(0, 50, n_rows)\n",
    "    ) * df[\n",
    "        \"inflation_multiplier\"\n",
    "    ]  # adding random noise\n",
    "\n",
    "    # Add previous day's demand\n",
    "    df[\"previous_days_demand\"] = df[\"demand\"].shift(1)\n",
    "    df[\"previous_days_demand\"].fillna(\n",
    "        method=\"bfill\", inplace=True\n",
    "    )  # fill the first row\n",
    "\n",
    "    # Drop temporary columns\n",
    "    df.drop(columns=[\"inflation_multiplier\", \"harvest_effect\", \"month\"], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ea0d092-22c8-4f1c-be23-2ef6572d9fc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Generate data and save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7beeb217-6890-4561-b614-830ff1e2e70a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>weekend</th>\n",
       "      <th>holiday</th>\n",
       "      <th>price_per_kg</th>\n",
       "      <th>promo</th>\n",
       "      <th>demand</th>\n",
       "      <th>previous_days_demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2025-07-14 03:38:33.456903</td>\n",
       "      <td>34.130183</td>\n",
       "      <td>1.454065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.449177</td>\n",
       "      <td>0</td>\n",
       "      <td>999.306290</td>\n",
       "      <td>1356.418398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>2025-07-15 03:38:33.456902</td>\n",
       "      <td>32.353643</td>\n",
       "      <td>9.462859</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.856503</td>\n",
       "      <td>0</td>\n",
       "      <td>842.129427</td>\n",
       "      <td>999.306290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>2025-07-16 03:38:33.456901</td>\n",
       "      <td>18.816833</td>\n",
       "      <td>0.391470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.326429</td>\n",
       "      <td>0</td>\n",
       "      <td>990.616709</td>\n",
       "      <td>842.129427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>2025-07-17 03:38:33.456900</td>\n",
       "      <td>34.533012</td>\n",
       "      <td>2.120477</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970131</td>\n",
       "      <td>0</td>\n",
       "      <td>1068.802075</td>\n",
       "      <td>990.616709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>2025-07-18 03:38:33.456899</td>\n",
       "      <td>23.057202</td>\n",
       "      <td>2.365705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.049931</td>\n",
       "      <td>0</td>\n",
       "      <td>1019.486305</td>\n",
       "      <td>1068.802075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>2025-07-19 03:38:33.456898</td>\n",
       "      <td>34.810165</td>\n",
       "      <td>3.089005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.035149</td>\n",
       "      <td>0</td>\n",
       "      <td>1329.564672</td>\n",
       "      <td>1019.486305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>2025-07-20 03:38:33.456898</td>\n",
       "      <td>29.208905</td>\n",
       "      <td>3.673292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.518098</td>\n",
       "      <td>0</td>\n",
       "      <td>1413.143402</td>\n",
       "      <td>1329.564672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>2025-07-21 03:38:33.456897</td>\n",
       "      <td>16.428676</td>\n",
       "      <td>4.077782</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.268979</td>\n",
       "      <td>0</td>\n",
       "      <td>1093.207186</td>\n",
       "      <td>1413.143402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>2025-07-22 03:38:33.456896</td>\n",
       "      <td>32.067512</td>\n",
       "      <td>2.734454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.762317</td>\n",
       "      <td>0</td>\n",
       "      <td>1069.939894</td>\n",
       "      <td>1093.207186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>2025-07-23 03:38:33.456895</td>\n",
       "      <td>31.938203</td>\n",
       "      <td>13.883486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.153301</td>\n",
       "      <td>0</td>\n",
       "      <td>994.409540</td>\n",
       "      <td>1069.939894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>2025-07-24 03:38:33.456894</td>\n",
       "      <td>18.024055</td>\n",
       "      <td>7.544061</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.610703</td>\n",
       "      <td>0</td>\n",
       "      <td>1078.323183</td>\n",
       "      <td>994.409540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>2025-07-25 03:38:33.456893</td>\n",
       "      <td>20.681067</td>\n",
       "      <td>18.820490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.533488</td>\n",
       "      <td>0</td>\n",
       "      <td>1001.499120</td>\n",
       "      <td>1078.323183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>2025-07-26 03:38:33.456892</td>\n",
       "      <td>16.010132</td>\n",
       "      <td>7.705941</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.632498</td>\n",
       "      <td>1</td>\n",
       "      <td>1548.922141</td>\n",
       "      <td>1001.499120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>2025-07-27 03:38:33.456890</td>\n",
       "      <td>18.766455</td>\n",
       "      <td>6.274840</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.806554</td>\n",
       "      <td>0</td>\n",
       "      <td>1283.412724</td>\n",
       "      <td>1548.922141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2025-07-28 03:38:33.456889</td>\n",
       "      <td>27.948793</td>\n",
       "      <td>23.705246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.829464</td>\n",
       "      <td>0</td>\n",
       "      <td>1090.592622</td>\n",
       "      <td>1283.412724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2025-07-29 03:38:33.456888</td>\n",
       "      <td>28.661072</td>\n",
       "      <td>10.329865</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.290591</td>\n",
       "      <td>0</td>\n",
       "      <td>936.465043</td>\n",
       "      <td>1090.592622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2025-07-30 03:38:33.456887</td>\n",
       "      <td>10.821693</td>\n",
       "      <td>3.575645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.897473</td>\n",
       "      <td>0</td>\n",
       "      <td>1016.336362</td>\n",
       "      <td>936.465043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2025-07-31 03:38:33.456886</td>\n",
       "      <td>21.108560</td>\n",
       "      <td>6.221089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.093864</td>\n",
       "      <td>0</td>\n",
       "      <td>1063.698477</td>\n",
       "      <td>1016.336362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2025-08-01 03:38:33.456884</td>\n",
       "      <td>29.451301</td>\n",
       "      <td>5.021463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.493085</td>\n",
       "      <td>0</td>\n",
       "      <td>979.255235</td>\n",
       "      <td>1063.698477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2025-08-02 03:38:33.456879</td>\n",
       "      <td>19.261458</td>\n",
       "      <td>0.438381</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.610422</td>\n",
       "      <td>0</td>\n",
       "      <td>1207.188828</td>\n",
       "      <td>979.255235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  ...  previous_days_demand\n",
       "980 2025-07-14 03:38:33.456903  ...           1356.418398\n",
       "981 2025-07-15 03:38:33.456902  ...            999.306290\n",
       "982 2025-07-16 03:38:33.456901  ...            842.129427\n",
       "983 2025-07-17 03:38:33.456900  ...            990.616709\n",
       "984 2025-07-18 03:38:33.456899  ...           1068.802075\n",
       "985 2025-07-19 03:38:33.456898  ...           1019.486305\n",
       "986 2025-07-20 03:38:33.456898  ...           1329.564672\n",
       "987 2025-07-21 03:38:33.456897  ...           1413.143402\n",
       "988 2025-07-22 03:38:33.456896  ...           1093.207186\n",
       "989 2025-07-23 03:38:33.456895  ...           1069.939894\n",
       "990 2025-07-24 03:38:33.456894  ...            994.409540\n",
       "991 2025-07-25 03:38:33.456893  ...           1078.323183\n",
       "992 2025-07-26 03:38:33.456892  ...           1001.499120\n",
       "993 2025-07-27 03:38:33.456890  ...           1548.922141\n",
       "994 2025-07-28 03:38:33.456889  ...           1283.412724\n",
       "995 2025-07-29 03:38:33.456888  ...           1090.592622\n",
       "996 2025-07-30 03:38:33.456887  ...            936.465043\n",
       "997 2025-07-31 03:38:33.456886  ...           1016.336362\n",
       "998 2025-08-01 03:38:33.456884  ...           1063.698477\n",
       "999 2025-08-02 03:38:33.456879  ...            979.255235\n",
       "\n",
       "[20 rows x 9 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = generate_apple_sales_data_with_promo_adjustment(base_demand=1_000, n_rows=1_000)\n",
    "\n",
    "data[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5949704-675e-4de5-9438-eb5c64d207e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Using MLflow Tracking to keep track of training\n",
    "Now that we have our data set and have seen a little bit of how runs are recorded, let's dive in to using MLflow to tracking a training iteration.\n",
    "\n",
    "To start with, we will need to import our required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0fb4d07-8ec0-41e0-af6f-4c93b4b973a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ce1fcc1-ca50-4fea-bff1-9645ec5055f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Since we are running inside databricks we do not need to specify full uri. However, if we run this notebook locally we will need to set the following values\n",
    "\n",
    "```python\n",
    "os.environ[\"DATABRICKS_HOST\"] = \"https://dbc-1234567890123456.cloud.databricks.com\" # set to your server URI\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = \"dapixxxxxxxxxxxxx\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_experiment(\"/your-experiment\")\n",
    "```\n",
    "For details refer to https://docs.databricks.com/aws/en/mlflow/tracking#where-mlflow-runs-are-logged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f30bbdf-d522-4bc9-ac38-1db0391bc829",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "\n",
    "import os\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = \"<your-access-token>\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "027148c5-2f50-4119-a59a-bb8d3340fe98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We will define a few more constants that we're going to be using when logging our training events to MLflow in the form of runs. We'll start by defining an Experiment that will be used to log runs to. There is a parent-child relationship of Experiments to Runs. The utility of this relationship will be used once we start iterating over some ideas and need to compare the results of our tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f051c1d3-cfef-4648-bb59-c04145ee6c20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sets the current active experiment to the \"Apple_Models\" experiment and\n",
    "# returns the Experiment metadata\n",
    "apple_experiment = mlflow.set_experiment(\"/Users/dimitar_pg13@hotmail.com/Apple_Models\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"apples_rf_test\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"rf_apples\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec896888-b79d-4d07-aab4-9dfbf1a74164",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "With these variables defined, we can start training a model.\n",
    "\n",
    "Firstly, let's look at what we're going to be running. Following the code display, we'll look at an annotated version of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b956298f-4776-4236-be4d-976a895933c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 View Logged Model at: https://dbc-b2d30165-76df.cloud.databricks.com/ml/experiments/2387429575046603/models/m-2b6882959fc442a3a26fa33cdb5f3111?o=4476931374519718\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-07cf0639-eff2-4196-9004-174a0e326544/lib/python3.11/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features and target and drop irrelevant date field and target field\n",
    "X = data.drop(columns=[\"date\", \"demand\"])\n",
    "y = data[\"demand\"]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 4,\n",
    "    \"bootstrap\": True,\n",
    "    \"oob_score\": False,\n",
    "    \"random_state\": 888,\n",
    "}\n",
    "\n",
    "# Train the RandomForestRegressor\n",
    "rf = RandomForestRegressor(**params)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "# Calculate error metrics\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "# Assemble the metrics we're going to write into a collection\n",
    "metrics = {\"mae\": mae, \"mse\": mse, \"rmse\": rmse, \"r2\": r2}\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(sk_model=rf, input_example=X_val, name=artifact_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Logging_First_Model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}